{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.ewatercycle.org/img/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study 3: replace internal evaporation module of PCRGlobWB2.0 with external data source\n",
    "This notebooks demonstrates how to use eWaterCycle to 'interfere' in a model. Every timestep, the evaporation of PCRGlobWB is 'corrected' to reflect the evaporation as measured by FLuxnet data. In this way, the model is forced by both precipitation and evaporation. Since we are only using one (point) measurement as 'the evaporation' of the entire basin, this (of course) leads to a rather different prediction for discharge. Which one is 'better' is, as always, in the eye of the beholder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements\n",
    "We'll be using the following modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#OS related \n",
    "from os import environ, remove\n",
    "from os.path import abspath\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from configparser import ConfigParser\n",
    "\n",
    "#Time and time object related\n",
    "import time\n",
    "from datetime import datetime\n",
    "from cftime import num2date\n",
    "\n",
    "#calculations and plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import xarray as xr\n",
    "from scipy import optimize\n",
    "from tqdm import tqdm\n",
    "\n",
    "#cartography (drawing maps)\n",
    "from cartopy.io import shapereader\n",
    "from cartopy import crs\n",
    "\n",
    "#hydrological specific non eWaterCycle\n",
    "import hydrostats.metrics as hm\n",
    "import hydrostats.visual as hv\n",
    "\n",
    "#eWaterCycle specific\n",
    "from ewatercycle.observation.grdc import get_grdc_data\n",
    "from grpc4bmi.bmi_client_docker import BmiClientDocker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle #this is only temporary, because we want to store output data at the end of a model run, so we can shut down the server if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions needed\n",
    "\n",
    "The following functions are needed for this experiment.\n",
    "\n",
    "TO DO: all of these need to become part of libraries, or at least be moved to a supporting .py file that is imported above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes an BMI model object, extracts variable and stores it \n",
    "# as an xarray object. For this to work, the variable does need to have a propper\n",
    "# setup grid. See the BMI documentation on grids.\n",
    "\n",
    "def var_to_xarray(model, variable):\n",
    "    # Get grid properties from model (x = latitude !!)\n",
    "    # could be speedup, lots of bmi calls are done here that dont change between updates\n",
    "    shape = model.get_grid_shape(model.get_var_grid(variable))\n",
    "    lat = model.get_grid_x(model.get_var_grid(variable))\n",
    "    lon = model.get_grid_y(model.get_var_grid(variable))\n",
    "    time = num2date(model.get_current_time(), model.get_time_units())\n",
    "\n",
    "    # Get model data for variable at current timestep\n",
    "    data = model.get_value(variable)\n",
    "    data = np.reshape(data, shape)\n",
    "\n",
    "    # Create xarray object\n",
    "    da = xr.DataArray(data, \n",
    "                      coords = {'longitude': lon, 'latitude': lat, 'time': time}, \n",
    "                      dims = ['latitude', 'longitude'],\n",
    "                      name = variable,\n",
    "                      attrs = {'units': model.get_var_units(variable)}\n",
    "                     )\n",
    "\n",
    "    # Masked invalid values on return array:\n",
    "    return da.where(da != -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following two functions translate lat,lon coordinates into BMI model \n",
    "# indices, which are used to get and set variable values.\n",
    "\n",
    "def lat_lon_to_closest_variable_indices(model, variable, lats, lons):\n",
    "    \n",
    "    #get shape of model grid and lat-lon coordinates of grid\n",
    "    shape = model.get_grid_shape(model.get_var_grid(variable))\n",
    "    latModel = model.get_grid_x(model.get_var_grid(variable))\n",
    "    lonModel = model.get_grid_y(model.get_var_grid(variable))\n",
    "    nx = len(latModel)\n",
    "    \n",
    "    #for each coordinate given, determine where in the grid they fall and \n",
    "    #calculate 1D indeces\n",
    "    if len(lats) == 1:\n",
    "        idx = np.abs(latModel - lats).argmin()\n",
    "        idy = np.abs(lonModel - lons).argmin()\n",
    "        output = idx+nx*idy\n",
    "    else:\n",
    "        output=[]\n",
    "        for [lat,lon] in [lats,lons]:\n",
    "            idx = np.abs(latModel - lat).argmin()\n",
    "            idy = np.abs(lonModel - lon).argmin()\n",
    "            output.append(idx+nx*idy) \n",
    "\n",
    "    return np.array(output)\n",
    "\n",
    "def lat_lon_boundingbox_to_variable_indices(model, variable, latMin, latMax, lonMin, lonMax):\n",
    "    #get shape of model grid and lat-lon coordinates of grid\n",
    "    shape = model.get_grid_shape(model.get_var_grid(variable))\n",
    "    latModel = model.get_grid_x(model.get_var_grid(variable))\n",
    "    lonModel = model.get_grid_y(model.get_var_grid(variable))\n",
    "    nx = len(latModel)\n",
    "\n",
    "    idx = [i for i,v in enumerate(latModel) if ((v > latMin) and (v < latMax))]\n",
    "    idy = [i for i,v in enumerate(lonModel) if ((v > lonMin) and (v < lonMax))]\n",
    "    \n",
    "    output = []\n",
    "    for x in idx:\n",
    "        for y in idy:\n",
    "            output.append(x + nx*y)\n",
    "    \n",
    "    return np.array(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of files created for this experiment\n",
    "\n",
    "### for PCRGlobWB2.0\n",
    "\n",
    "- `merrimack_05min_era5.ini` This file is identical to the file with the same name used in the big comparison study. The only difference is that the time period (variables startTime and endTime) have been set to 2002-01-01 and 2002-12-31 respectivly. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and parameters to run this experiment\n",
    "The settings below are seperated in settings that 'belong' to the experiment, those that belong to PCRGlobWB or those that belong with MARRMoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for this experiment\n",
    "\n",
    "# The project home directory where data lives and output should be written\n",
    "PROJECT_HOME = Path(os.path.abspath(\"/mnt/home/user42\"))\n",
    "DATA_HOME = Path(os.path.abspath(\"/mnt/data/examples/technical_paper\"))\n",
    "\n",
    "# Settings for GRDC station for final comparison of streamflow\n",
    "station_id = '4147380' # GRDC station ID\n",
    "basin_name = 'Merrimack'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for PCRGlobWB2.0\n",
    "PCRGlob_input_dir=str(DATA_HOME / 'pcr-globwb' / 'input')\n",
    "PCRGlob_Ref_output_dir=str(PROJECT_HOME / 'case2' / 'PCRGlobREFOutput')\n",
    "PCRGlob_Exp_output_dir=str(PROJECT_HOME / 'case2' / 'PCRGlobExpOutput')\n",
    "#forcing_dir = '/mnt/data/examples/technical_paper/pcr-globwb/input/'\n",
    "\n",
    "PCRGlob_setting_file = str(PROJECT_HOME / 'technicalPaperExampleNotebooks' / 'settingFiles' \n",
    "                           / 'merrimack_05min_era5.ini')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start up a container for PCRGlob for the reference run \n",
    "# and initialize using the setting file\n",
    "PCRGlob_Ref_model = BmiClientDocker(image='ewatercycle/pcrg-grpc4bmi:setters', image_port=55555,\n",
    "\n",
    "                   input_dir=PCRGlob_input_dir,\n",
    "\n",
    "                   output_dir=PCRGlob_Ref_output_dir)\n",
    "\n",
    " \n",
    "\n",
    "PCRGlob_Ref_model.initialize(PCRGlob_setting_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start up a container for PCRGlob for the reference run \n",
    "# and initialize using the setting file\n",
    "PCRGlob_Exp_model = BmiClientDocker(image='ewatercycle/pcrg-grpc4bmi:setters', image_port=55555,\n",
    "\n",
    "                   input_dir=PCRGlob_input_dir,\n",
    "\n",
    "                   output_dir=PCRGlob_Exp_output_dir)\n",
    "\n",
    " \n",
    "\n",
    "PCRGlob_Exp_model.initialize(PCRGlob_setting_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, create variables needed during the experiment run\n",
    "PCRGlob_Ref_output = []\n",
    "PCRGlob_Exp_output = []\n",
    "\n",
    "PCRGlob_time_units = PCRGlob_Exp_model.get_time_units()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importaing evaporation data from Fluxnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the csv file downloaded from [TODO]\n",
    "fluxnetData = pd.read_csv('FLX_US-Ha1_FLUXNET2015_SUBSET_DD_1991-2012_1-4.csv') #Read fluxnet data from exel\n",
    "fluxnetData['Datetime']=pd.to_datetime(fluxnetData['TIMESTAMP'],format='%Y%m%d')\n",
    "fluxnetData = fluxnetData.set_index('Datetime')\n",
    "\n",
    "#Select evaporation measured as latent heat flux from fluxnetdata\n",
    "#and rewrite evaporation from latent heat flux to m/day\n",
    "fluxnetEvaporation = fluxnetData['LE_F_MDS'] / (2.43 * 1000000) * 6772 ** 2 / (3600 * 24) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the experiment PCRGlobWB model one timestep, store the output\n",
    "PCRGlob_Exp_model.update()\n",
    "PCRGlob_Exp_output.append(var_to_xarray(PCRGlob_Exp_model, variable=\"discharge\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the experiment\n",
    "With all pieces in place, we can now start to run the actual experiment. Since both models (reference and epxeriment) do not interact, they can be run in seperate loops and (ideally) this should be done in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Reference Model Run\n",
      "Current time: 2002-02-07 00:00:00\r"
     ]
    }
   ],
   "source": [
    "print(f'Running Reference Model Run', flush=True)\n",
    "\n",
    "#the experiment model is used as central 'time keeper'\n",
    "while PCRGlob_Ref_model.get_current_time() < PCRGlob_Ref_model.get_end_time():\n",
    "    \n",
    "    #get the current time to print\n",
    "    time = num2date(PCRGlob_Ref_model.get_current_time(), PCRGlob_time_units)\n",
    "    print(f'Current time: {time}', end=\"\\r\")\n",
    "\n",
    "    #run the reference model for one timestep, store the output\n",
    "    PCRGlob_Ref_model.update()\n",
    "    PCRGlob_Ref_output.append(var_to_xarray(PCRGlob_Ref_model, variable=\"discharge\"))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Running Experiment', flush=True)\n",
    "\n",
    "#TODO: PCRGlobWB has a bug where we can only get and set variables after at least one time step has been run, ie. \n",
    "# after the first .update().\n",
    "#Run the experiment PCRGlobWB model one timestep, store the output\n",
    "PCRGlob_Exp_model.update()\n",
    "PCRGlob_Exp_output.append(var_to_xarray(PCRGlob_Exp_model, variable=\"discharge\"))\n",
    "\n",
    "\n",
    "#the experiment model is used as central 'time keeper'\n",
    "while PCRGlob_Exp_model.get_current_time() < PCRGlob_Exp_model.get_end_time():\n",
    "    \n",
    "    #get the current time to print\n",
    "    time = num2date(PCRGlob_Exp_model.get_current_time(), PCRGlob_time_units)\n",
    "    print(f'Current time: {time}', end=\"\\r\")\n",
    "    \n",
    "    #After PCRGlob has calculated all states, extract the time from the model, than use that to determine the evaporation \n",
    "    # at that time according to Fluxnet. Calculate the correction needed as a correction.\n",
    "\n",
    "    modelTimeAsDateTime = pd.to_datetime(num2date(PCRGlob_Exp_model.get_current_time(),PCRGlob_time_units).strftime())\n",
    "    \n",
    "    #get current from the model\n",
    "    ussd = PCRGlob_Exp_model.get_value('upper_soil_saturation_degree')\n",
    "    uss = PCRGlob_Exp_model.get_value('upper_soil_storage')\n",
    "    lse = PCRGlob_Exp_model.get_value('land_surface_evaporation')\n",
    "    bse = PCRGlob_Exp_model.get_value('bare_soil_evaporation') # Bare soil evaporation\n",
    "    cs = PCRGlob_Exp_model.get_value('channel_storage') # channel storage\n",
    "    \n",
    "    #calculate corrections to model state\n",
    "    muss =  1 / ussd * uss # maximum storage value of the upper soil layer\n",
    "    mlse = np.nanmean(lse) # Mean land surface evaporation will be compared with the fluxnet measured evaporation\n",
    "    flse = fluxnetEvaporation[modelTimeAsDateTime] / mlse\n",
    "    abse = bse * flse # \"Actual\" bare soil evaporation\n",
    "    cbse = abse - bse # correction bare soil evaporation\n",
    "    csBU = cs #back up of channel storage\n",
    "\n",
    "    \n",
    "    #depending on the state of a given cell, determine how to apply the correction. If too much water would be added (exceding maximum soil capacity)\n",
    "    # any excess is added to the chanel, ie. as direct runoff.\n",
    "    for j in range(len(uss)):\n",
    "        if uss[j] + cbse[j] > muss[j]:\n",
    "            # The correction addition exeeds the maximum storage capacity in the upper soil layer for pixel j. \n",
    "            # The additional water is redirected to the channel storage.\n",
    "            acs = (uss[j] + cbse[j]) - muss[j] # aditional channel storage\n",
    "            cs[j] = cs[j] + acs #Edit the channel storage in pixel j\n",
    "            uss[j] = muss[j] # Set the uppers soil storage for pixel j to maximum (the layer is full)\n",
    "\n",
    "        elif uss[j] + cbse[j] < 0:\n",
    "            # The correction addition reduces the storage capacity in the uppers soil layer to below zero.\n",
    "            # A negative storage value is not possible therefore the (remaining) water deficit is taken from the channel storage.\n",
    "            rfcs = (uss[j] + cbse[j]) # required from channel storage\n",
    "            cs[j] = cs[j] + rfcs #Edit the channel storage for pixel j\n",
    "            uss[j] = 0 #Edit the upper soil storage for pixel j to zero (the layer is empty)\n",
    "           \n",
    "        else:\n",
    "            # If the correction additon does not put the value of the soil storage above or below its limits the correction flux is just added.\n",
    "            uss[j] = uss[j] + cbse[j]\n",
    "            \n",
    "\n",
    "    \n",
    "    cussd = uss / muss # Corrected upper soil saturation degree\n",
    "\n",
    "    #correct NaN values\n",
    "    for j in range(len(uss)):\n",
    "        if np.isnan(cussd[j]):\n",
    "            cussd[j] = ussd[j]\n",
    "        if np.isnan(cs[j]):\n",
    "            cs[j]=csBU[j]\n",
    "            \n",
    "    \n",
    "    PCRGlob_Exp_model.set_value('upper_soil_saturation_degree', cussd) #After all the pixels have been corrected add the new saturation degrees to the model\n",
    "    PCRGlob_Exp_model.set_value('channel_storage', cs) #After all the pixels have been corrected add the new channel storage to the model\n",
    "    \n",
    "    #Run the experiment PCRGlobWB model one timestep, store the output\n",
    "    PCRGlob_Exp_model.update()\n",
    "    PCRGlob_Exp_output.append(var_to_xarray(PCRGlob_Exp_model, variable=\"discharge\"))\n",
    "    \n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clean up after the model run\n",
    "The models have to be 'finalized', which deletes any temporary files and the containers have to be shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#before deleting the containers, get the start and end dates of the model run\n",
    "# needed to select the right period from the GRDC Observations below\n",
    "\n",
    "dstart = num2date(PCRGlob_Ref_model.get_start_time(),PCRGlob_time_units).strftime(format = '%Y-%m-%d')\n",
    "dend = num2date(PCRGlob_Ref_model.get_end_time(),PCRGlob_time_units).strftime(format = '%Y-%m-%d')\n",
    "\n",
    "\n",
    "PCRGlob_Ref_model.finalize()\n",
    "PCRGlob_Exp_model.finalize()\n",
    "\n",
    "\n",
    "del PCRGlob_Exp_model\n",
    "del PCRGlob_Ref_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('.\\..\\modelrunCase2Full.pckl', 'wb')\n",
    "pickle.dump([PCRGlob_Ref_output, PCRGlob_Exp_output],f)\n",
    "f.close()\n",
    "del f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import GRDC observations\n",
    "\n",
    "Read the GRDC data for the period of the experiment, for the station given above. \n",
    "If you are not on jupyter.ewatercycle.org or cartesius, download the GRDC https://www.bafg.de/GRDC/EN/02_srvcs/21_tmsrs/riverdischarge_node.html and set the directory below in GRDC_DATA_HOME env var.\n",
    "\n",
    "### TODO the four lines at the end of the cell should become part of the get_grdc_data function, which (I think) should return a dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on Cartesius:\n",
    "#environ['GRDC_DATA_HOME']= '/projects/0/wtrcycle/GRDC/GRDC_GCOSGTN-H_27_03_2019'\n",
    "\n",
    "#on jupyter.ewatercycle.org\n",
    "environ['GRDC_DATA_HOME']= '/mnt/data/grdc/dailies' \n",
    "\n",
    "observations = get_grdc_data(station_id, start_date=dstart, end_date=dend)\n",
    "grdc_obs = observations.to_dataframe().rename(columns = {'streamflow': 'GRDC'})\n",
    "grdc_lon = observations.attrs['grdc_longitude_in_arc_degree']\n",
    "grdc_lat = observations.attrs['grdc_latitude_in_arc_degree']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('.\\..\\modelrunCase2Full.pckl', 'rb')\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "del f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExp  = xr.concat(data[0], dim='time')\n",
    "dataRef  = xr.concat(data[1], dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(10, 10), dpi=120)\n",
    "\n",
    "dataExp.isel(time=-1).plot(ax=axs, cmap='YlGnBu', robust=True)\n",
    "axs.set_title('test')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'pcrglobwb_RolfCase2_discharge_map', bbox_inches='tight', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=.2\n",
    "\n",
    "# Write data for model output at GRDC location to pandas series,\n",
    "# Use padding and max to correct for GRDC station location error\n",
    "dataExpAtGRDCLocation = dataExp.sel(longitude=slice(grdc_lon-pad, grdc_lon+pad), \n",
    "                         latitude=slice(grdc_lat-pad, grdc_lat+pad)\n",
    "                        ).max(['longitude', 'latitude']\n",
    "                        ).rename('ERA5Exp'\n",
    "                        ).to_dataframe()\n",
    "\n",
    "dataExpAtGRDCLocation.index=dataExpAtGRDCLocation.index.to_datetimeindex()\n",
    "\n",
    "dataRefAtGRDCLocation = dataRef.sel(longitude=slice(grdc_lon-pad, grdc_lon+pad), \n",
    "                         latitude=slice(grdc_lat-pad, grdc_lat+pad)\n",
    "                        ).max(['longitude', 'latitude']\n",
    "                        ).rename('ERA5Ref'\n",
    "                        ).to_dataframe()\n",
    "\n",
    "dataRefAtGRDCLocation.index=dataRefAtGRDCLocation.index.to_datetimeindex()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine timeseries of ERA-Interim, ERA5 and GRDC observations in a pandas dataframe\n",
    "#df = pd.concat([dataExpAtGRDCLocation, dataRefAtGRDCLocation, grdc_obs],axis = 1)\n",
    "df = pd.concat([dataExpAtGRDCLocation, dataRefAtGRDCLocation, grdc_obs],axis = 1)\n",
    "\n",
    "# Note: the data come at different time stamps\n",
    "print(df.head())\n",
    "\n",
    "# For now, interpolating to get similar sets:\n",
    "df = df.fillna(method='ffill').dropna()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=120)\n",
    "df.plot(ax=ax)\n",
    "#ax.set_ylim(1000, 10000)\n",
    "ax.set_ylabel('Streamflow (m$^3$ s$^{-1}$)')\n",
    "ax.legend(['PCRGlobWB forced with Fluxnet','PCRGlobWB normal','Observations from GRDC'])\n",
    "\n",
    "dataset='ERA5Ref'\n",
    "yloc=0.6\n",
    "ax.text(1.02, yloc, f\"{dataset}:\\n\"\n",
    "        f\"NSE: {hm.nse(df[dataset], df['GRDC']):.2f} \\n\"\n",
    "        f\"KGE (2009): {hm.kge_2009(df[dataset], df['GRDC']):.2f}\\n\"\n",
    "        f\"SA: {hm.sa(df[dataset], df['GRDC']):.2f}\\n\"\n",
    "        f\"ME: {hm.me(df[dataset], df['GRDC']):.2f}\",\n",
    "        transform=ax.transAxes, va='top')\n",
    "\n",
    "fig.savefig(f'pcrglobwb_{basin_name}_hydrograph', bbox_inches='tight', dpi=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
